# Engram - 2-Line Description

## What & Why

**What**: Engram is a plug-and-play memory engine for AI agents that gives them long-term memory with just a few lines of code — works with any LLM, any storage, zero infrastructure.

**Why**: Building AI agents that remember? You shouldn't need to set up vector databases, manage embeddings, or write complex retrieval logic. Engram handles all of that so you can focus on building your agent.

---

## Alternative Versions

### Ultra-Short (Twitter/X)
Memory engine for AI agents. One import, any LLM, zero setup. Your agent remembers everything.

### Short (npm package description)
Plug-and-play memory engine for AI agents — one import, any LLM, any storage, and your agent never forgets

### Medium (GitHub About)
Type-safe, zero-infrastructure memory system for AI agents. Extract, store, and recall memories from conversations with any LLM. Works out of the box with in-memory storage, scales to SQLite. 150 tests, zero dependencies, 100% TypeScript.

### Elevator Pitch (30 seconds)
Building an AI agent that needs to remember things? Engram gives your agent long-term memory in 5 minutes. Just bring your LLM function — it works with OpenAI, Claude, or even free local models like Ollama. Zero setup, zero infrastructure. Your agent automatically learns what's important and recalls it when needed. Used in production by [companies/projects].

---

## Key Value Props (Pick 2-3)

1. **Zero Setup** → Works immediately with in-memory storage, no databases required
2. **BYOLLM** → Works with any LLM (OpenAI, Anthropic, Ollama, etc.)
3. **Smart Extraction** → Automatically identifies what's worth remembering
4. **Type-Safe** → Full TypeScript support with comprehensive types
5. **Zero Cost** → Works with free local models (tested with Ollama)
6. **Production Ready** → 150 tests, comprehensive documentation

---

## Target Audience

**Primary**: Developers building AI agents/chatbots with memory
**Secondary**: LLM application developers, AI researchers, indie hackers

**Pain Points Solved**:
- "I don't want to set up a vector database just for a simple chatbot"
- "My LLM doesn't remember previous conversations"
- "I need memory but don't want vendor lock-in"
- "Setting up RAG is too complex for my use case"

---

## Use This Description Where

- **npm package.json**: "Plug-and-play memory engine for AI agents — one import, any LLM, any storage, and your agent never forgets"
- **GitHub repo description**: "Type-safe memory engine for AI agents with zero infrastructure"
- **README.md hero**: Already has comprehensive description
- **Social media posts**: Use "Ultra-Short" version
- **Blog posts**: Use "Elevator Pitch" version
- **Conference talks**: Use "Medium" + "Why" explanation
